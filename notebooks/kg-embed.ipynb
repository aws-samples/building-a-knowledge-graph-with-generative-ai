{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3718663f-1dfb-4cb2-a7af-36aa78c6c0c4",
   "metadata": {},
   "source": [
    "# Building a knowledge graph with an LLM\n",
    "\n",
    "This notebook shows how to build up a knowledge base from unstructured data using a large language model (LLM). This approach is useful if you have a lot of unstructured data like meeting notes or short articles, and you want to automatically see the relationships between different concepts.\n",
    "\n",
    "Our approach starts by extracting a list of nodes and entities using Anthropic's Claude 3 model via Amazon Bedrock. We take the resulting nodes and entities and store them in Amazon Neptune, a graph database. Then we can use the typical set of graph visualizations and queries to understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80184f56",
   "metadata": {},
   "source": [
    "// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "// SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d7e66",
   "metadata": {},
   "source": [
    "## Load local configuration\n",
    "\n",
    "Create the file `config.yml` and then add settings for your Neptune graph ID and AWS region. For example:\n",
    "\n",
    "    aws:\n",
    "        region: us-east-1\n",
    "    neptune:\n",
    "        graph: your_neptune_analytics_graph_id\n",
    "\n",
    "You should not include `config.yml` in your version control. If you use Git, add it to your `.gitignore` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config = yaml.safe_load(open(\"config.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ce2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%opencypher_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248c2b6-728a-4383-b458-f94a89727baf",
   "metadata": {},
   "source": [
    "## Install dependencies and load data\n",
    "\n",
    "We'll use the `datasets` module to load a sample set of financial news articles, and the `neo4j` library to interact with Neptune programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d3f45-44ee-481f-9836-ad6575f55c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet boto3 botocore langchain datasets neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798bcf5-a6c6-4ff3-a3f1-8deac51c91bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lzma\n",
    "\n",
    "lines = []\n",
    "with lzma.open('/home/ec2-user/SageMaker/kleister-nda/train/in.tsv.xz', mode='rt', encoding='utf-8') as fid:\n",
    "    for line in fid:\n",
    "        fields = line.split('\\t')\n",
    "        lines.append(fields[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad21e7-ed5f-4ed2-8d7e-d6a76d7ebd2f",
   "metadata": {},
   "source": [
    "## Bedrock setup\n",
    "\n",
    "Here we'll define helper methods to use both Claude and Meta's Llama-2 model. This includes methods to invoke the models for regular chat, and methods that have prompts designed for node and entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce6cbe-9cd0-4fba-8462-d7fcf02f3abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9211f-d1e0-406d-a1a9-298634e81d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llamaModelId = 'meta.llama2-70b-chat-v1' \n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime', \n",
    "    region_name=config['aws']['region']\n",
    ")\n",
    "\n",
    "def call_llama(query):\n",
    "\n",
    "    prompt = f\"[INST]{query}[/INST]\"\n",
    "    llamaPayload = json.dumps({ \n",
    "    \t'prompt': prompt,\n",
    "        'max_gen_len': 512,\n",
    "    \t'top_p': 0.9,\n",
    "    \t'temperature': 0.2\n",
    "    })\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=llamaPayload, \n",
    "        modelId=llamaModelId, \n",
    "        accept='application/json', \n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    body = response.get('body').read().decode('utf-8')\n",
    "    response_body = json.loads(body)\n",
    "    return response_body['generation'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c57468-a331-446c-82e9-3a525e4e5c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_llama(\"Tell me a story about Mars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08395a-bc0f-487d-920c-d9c1491c6ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "claudeModelId = 'anthropic.claude-3-sonnet-20240229-v1:0' \n",
    "\n",
    "def call_claude(query):\n",
    "\n",
    "    claudePayload = json.dumps({ \n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        'max_tokens': 2048,\n",
    "    \t\"messages\": [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": query\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=claudePayload, \n",
    "        modelId=claudeModelId, \n",
    "        accept='application/json', \n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    body = response.get('body').read().decode('utf-8')\n",
    "\n",
    "    response_body = json.loads(body)\n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df3066-1ac3-492b-b41e-89a01e37a0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_claude(\"Tell me a story about Mars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262765a4-dbd1-4a42-aff6-b234a9915da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_llama_kg(query):\n",
    "\n",
    "    prompt = \"\"\"[INST]You are a robot that extracts information from financial news to build a knowledge graph. You only output JSON. Nodes represent entities, like a company.  Edges represent the relationships between nodes, like the fact that a person is the CEO of a company. When extracting nodes, it's vital to ensure consistency. If a node, such as \"Acme Corp\", is mentioned multiple times in the text but is referred to by different names (e.g., \"Acme\"), always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"Acme Corp\" as the node ID. \n",
    "\n",
    "Example input: \"John Doe was recently named the CEO of Acme Corp.\"\n",
    "Example output: \n",
    "\n",
    "{\n",
    "\"nodes\": [\n",
    "   {\n",
    "        \"label\": \"person\",\n",
    "        \"id\": \"John Doe\",\n",
    "        \"firstName\": \"john\",\n",
    "        \"lastName\": \"doe\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"company\",\n",
    "        \"id\": \"Acme Corp\",\n",
    "    }\n",
    "],\n",
    "\"edges\": [\n",
    "    {\n",
    "        \"label\": \"executive\",\n",
    "        \"id\": \"e-john-doe-acme-corp\",\n",
    "        \"node1\": \"John Doe\",\n",
    "        \"node2\": \"Acme Corp\"\n",
    "    }\n",
    "]\n",
    "}\n",
    "\n",
    "Use the given format to extract information from the following input, responding only with JSON and no extra text:\n",
    "\"\"\"\n",
    "    \n",
    "    llamaPayload = json.dumps({ \n",
    "    \t'prompt': prompt + query + \"[/INST]\",\n",
    "        'max_gen_len': 2048,\n",
    "    \t'top_p': 0.9,\n",
    "    \t'temperature': 0.2\n",
    "    })\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=llamaPayload, \n",
    "        modelId=llamaModelId, \n",
    "        accept='application/json', \n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    body = response.get('body').read().decode('utf-8')\n",
    "    response_body = json.loads(body)\n",
    "    return response_body['generation'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86cc81a-994b-4e96-b581-90f9dca5ed24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_llama_kg(j):\n",
    "    c = j.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    idx = c.find('{')\n",
    "    return json.loads(c[idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a41ba5-3d95-497c-95ce-ac116e45cc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_claude_kg(query):\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "Below is an article from a financial news source. Your job is to extract nodes and edges to build a knowledge graph. A node is an entity like a company. An edge is a relationship between two nodes, like \"John Smith is the CEO of Acme Corp\". When extracting nodes, it's vital to ensure consistency. If a node, such as \"Acme Corp\", is mentioned multiple times in the text but is referred to by different names (e.g., \"Acme\"), always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"Acme Corp\" as the node ID. Use camel case for node id, like \"acme_corp\" instead of \"Acme Corp\". If you find additional information, add it as a property on the node or edge. For example, if Acme Corp is a mining company, you can add a property \"industry\" set to \"mining\". \n",
    "\n",
    "Each node should have at least an `id` field and a `type` field. The `id` is the unique identifier, and the `type` is the type of entity, like 'company' or 'executive'. You can include other properties if you find them.\n",
    "\n",
    "Example output:\n",
    "\n",
    "<json>\n",
    "{\n",
    "  \"nodes\": [\n",
    "      {\n",
    "          \"id\": \"acme_corp\",\n",
    "          \"type\": \"company\",\n",
    "          \"name\": \"Acme Corp\",\n",
    "          \"industry\": \"chemicals\"\n",
    "      },\n",
    "      {\n",
    "          \"id\": \"john_doe\",\n",
    "          \"type\": \"executive\",\n",
    "          \"name\": \"John Doe\"\n",
    "      }\n",
    "  ],\n",
    "  \"edges\": [\n",
    "      {\n",
    "          \"source\": \"acme_corp\",\n",
    "          \"target\": \"john_doe\",\n",
    "          \"type\": \"employee\",\n",
    "          \"employee_type\": \"CEO\"\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "</json>\n",
    "\n",
    "<article>\n",
    "ARTICLE_HERE\n",
    "</article>\n",
    "\n",
    "You must output only valid JSON. Be concise - do not provide any extra text before or after the JSON.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = prompt_template.replace(\"ARTICLE_HERE\", query)\n",
    "    \n",
    "    claudePayload = json.dumps({ \n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        'max_tokens': 2048,\n",
    "    \t\"messages\": [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=claudePayload, \n",
    "        modelId=claudeModelId, \n",
    "        accept='application/json', \n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    body = response.get('body').read().decode('utf-8')\n",
    "\n",
    "    response_body = json.loads(body)\n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb6f93-f3a8-46cf-b4eb-87b1d8368063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_claude_kg(j):\n",
    "    if '<json>' in j:\n",
    "        idx1 = j.find('<json>')\n",
    "        idx2 = j.find('</json>')\n",
    "        s = j[idx1+6:idx2]\n",
    "        return(json.loads(s))\n",
    "    elif '```json' in j:\n",
    "        idx1 = j.find('```json')\n",
    "        idx2 = j.rfind('```')\n",
    "        s = j[idx1+7:idx2]\n",
    "        return(json.loads(s))\n",
    "    else:\n",
    "        raise Exception(\"Unknown Claude response format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedModelId = 'amazon.titan-embed-text-v1' \n",
    "\n",
    "def call_embed(query):\n",
    "\n",
    "    accept = 'application/json' \n",
    "    content_type = 'application/json'\n",
    "    body = json.dumps({\n",
    "        \"inputText\": query,\n",
    "    })\n",
    "\n",
    "    # Invoke model \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, \n",
    "        modelId=embedModelId, \n",
    "        accept=accept, \n",
    "        contentType=content_type\n",
    "    )\n",
    "\n",
    "    # Print response\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    embedding = response_body.get('embedding')\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e1573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "call_embed(\"example text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a1cd4-d16f-4564-a368-76fd95b464c0",
   "metadata": {},
   "source": [
    "## Node and edge extraction\n",
    "\n",
    "Let's look at a single article and test our extraction methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6611d9a-cc02-4642-979d-9a0a2a96947d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119e040-e651-4b21-8596-1a16f975b67b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a73ed-1c2d-4224-a7ee-6f2a6af57ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "j = call_llama_kg(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3c3d5-f7df-4827-aa54-0049bb77007e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d29ccb-83ee-45dd-aa0a-01f614264c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "j = call_claude_kg(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ce83c-5c85-4671-8283-7f64465e7e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d1b93-820e-4cdb-bfb6-0732c638e63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(format_claude_kg(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5978cba-1caf-4fd3-a691-918fd0383433",
   "metadata": {},
   "source": [
    "### Neptune\n",
    "\n",
    "Let's check connectivity to the cluster and then try a few Cypher queries using Bolt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "graph_client = boto3.client('neptune-graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph_client.execute_query(\n",
    "    graphIdentifier=config['neptune']['graphid'],\n",
    "    queryString='MATCH (p:company) RETURN p.name AS name',\n",
    "    language='OPEN_CYPHER',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['payload'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b639c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_graph(graph_client, query):\n",
    "    response = graph_client.execute_query(\n",
    "        graphIdentifier=config['neptune']['graphid'],\n",
    "        queryString=query,\n",
    "        language='OPEN_CYPHER',\n",
    "    )\n",
    "    return json.loads(response['payload'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b82b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_graph(graph_client, 'MATCH (p:company) RETURN p.name AS name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graph(graph_client, query):\n",
    "    graph_client.execute_query(\n",
    "        graphIdentifier=config['neptune']['graphid'],\n",
    "        queryString=query,\n",
    "        language='OPEN_CYPHER',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31110b3-913a-481a-822b-4995b4aeabe2",
   "metadata": {},
   "source": [
    "### Process a few articles\n",
    "\n",
    "Here we'll pick a few random articles from the dataset and process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308abc4-8c45-4648-9689-1d9d75ad1140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_indices = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f2fac-55dc-4e05-8b2c-57f161df133e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_articles = len(dataset['train'])\n",
    "max_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47daab-3c91-4502-9ceb-ea5629ba06ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sanitize_prop(s):\n",
    "    t = str(s)\n",
    "    return t.replace('\"', '').replace(\"'\", \"\").replace('[', '').replace(']', '')\n",
    "\n",
    "def insert_node(nid, nlabel, nprops, graph_client):\n",
    "    propstr = []\n",
    "    for p in nprops.keys():\n",
    "        propstr.append(f\"{p}: '{sanitize_prop(nprops[p])}'\")\n",
    "    q = \"MERGE (:\" + nlabel + \" {\" + \",\".join(propstr) + \"})\"\n",
    "    print(f\"Query: {q}\")\n",
    "    update_graph(graph_client, q)\n",
    "    \n",
    "def insert_edge(elabel, en1, en2, et1, et2, eprops, graph_client):\n",
    "    eprops['name'] = elabel\n",
    "    propstr = []\n",
    "    for p in eprops.keys():\n",
    "        propstr.append(f\"{p}: '{eprops[p]}'\")\n",
    "    print(f\"eprops: {json.dumps(eprops)}\")\n",
    "    q = \"MATCH (\" + en1 + \":\" + et1 + \" {name: '\" + en1 + \"'}), (\" + en2 + \":\" + et2 + \" {name: '\" + en2 + \"'}) \" + \\\n",
    "        \"CREATE (\" + en1 + \")-[:\" + elabel+ \" {\" + \",\".join(propstr) + \"}]->(\" + en2 + \")\"\n",
    "    print(f\"Query: {q}\")\n",
    "    update_graph(graph_client, q)\n",
    "    \n",
    "def add_embedding(nid, embedding, graph_client):\n",
    "    q = \"MATCH (n) WHERE n.name in ['\" + nid + \"'] CALL neptune.algo.vectors.upsert(n, \" + str(embedding) + \") \" + \\\n",
    "        \"YIELD node, embedding, success RETURN node, embedding, success\"\n",
    "    update_graph(graph_client, q)\n",
    "\n",
    "def process_article(a, text_embed, graph_client):\n",
    "    n = a['nodes']\n",
    "    e = a['edges']\n",
    "    n_types = []\n",
    "    e_types = []\n",
    "    id_label_map = {}\n",
    "    \n",
    "    print(f\"Processing nodes: {len(n)}\")\n",
    "    for node in n:\n",
    "        try:\n",
    "            nid = node['id']\n",
    "            nlabel = node['type']\n",
    "            n_types.append(nlabel)\n",
    "\n",
    "            nprops = {}\n",
    "            nprops['name'] = nid\n",
    "            for k in node.keys():\n",
    "                if k in ['id', 'type', 'name']:\n",
    "                    continue\n",
    "                else:\n",
    "                    nprops[k] = node[k]\n",
    "            if 'name' in node:\n",
    "                nprops['nname'] = node['name']\n",
    "\n",
    "            insert_node(nid, nlabel, nprops, graph_client)\n",
    "            add_embedding(nid, text_embed, graph_client)\n",
    "            id_label_map[nid] = nlabel\n",
    "        except Exception as ee: \n",
    "            print(f\"Unable to process node {node} - {ee}\")\n",
    "    print(f\"Processing edges: {len(e)}\")\n",
    "    for edge in e:\n",
    "        try:\n",
    "            elabel = edge['type']\n",
    "            e_types.append(elabel)\n",
    "            en1 = edge['source']\n",
    "            en2 = edge['target']\n",
    "            et1 = id_label_map[en1]\n",
    "            et2 = id_label_map[en2]\n",
    "\n",
    "            eprops = {}\n",
    "            for k in edge.keys():\n",
    "                if k in ['source', 'type', 'target']:\n",
    "                    continue\n",
    "                else:\n",
    "                    eprops[k] = edge[k]\n",
    "\n",
    "            insert_edge(elabel, en1, en2, et1, et2, eprops, graph_client)\n",
    "        except Exception as ee: \n",
    "            print(f\"Unable to process edge {edge} - {ee}\")\n",
    "          \n",
    "    return n_types, e_types\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3ca74-b62c-4e0b-99c9-25b16d9e4a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for adx in article_indices:\n",
    "    print(f\"Article number {adx}\")\n",
    "    text = lines[adx]\n",
    "    text_embed = call_embed(text)\n",
    "    raw = call_claude_kg(text)\n",
    "    print(f\"Got Claude answer: {raw}\")\n",
    "    answer = format_claude_kg(raw)\n",
    "    print(f\"Claude JSON: {json.dumps(answer)}\")\n",
    "    process_article(answer, text_embed, graph_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%oc\n",
    "\n",
    "MATCH (n) \n",
    "WHERE n.name in ['albitar_oncology_consulting']\n",
    "CALL neptune.algo.vectors.get(n)\n",
    "YIELD node, embedding\n",
    "RETURN n.code, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d6558-dfe5-4bd0-9aad-67cd450e691f",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "Now we can use regular Neptune queries to visualize the data. For example, let's say we have a company named `armanino`. First we can make sure we have this company in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a13ed-0b20-45c4-86b7-6b6c7e1c69c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "\n",
    "MATCH (a:company {name: 'albitar_oncology_consulting'}) RETURN a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11797e89-7908-4e29-91d1-54be802a364e",
   "metadata": {},
   "source": [
    "Next we can run a Cypher query to show this company and all its relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40dabf-e6ce-40f7-81f0-756675104153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%oc\n",
    "\n",
    "MATCH (n {name: 'albitar_oncology_consulting'}) \n",
    "MATCH (n)-[r]-(m)\n",
    "RETURN n,r, m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048057b7-e465-402f-8903-9228d20274b2",
   "metadata": {},
   "source": [
    "This Gremlin query is similar but will label each node and edge with a more descriptive label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3670e16-760d-4b2b-ac4a-00f049092ca3",
   "metadata": {},
   "source": [
    "## Graph RAG\n",
    "\n",
    "A more sophisticated way to use the graph is to follow this process.\n",
    "\n",
    "* First, create an embedding of the query.\n",
    "* Second, query the graph for any related nodes using vector search.\n",
    "* Extract a subgraph that includes the related nodes to a certain depth.\n",
    "* Include the subgraph as context to the overall response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_vector_search(graph_client, embedding):\n",
    "    q = \"CALL neptune.algo.vectors.topKByEmbedding(\" + str(embedding) + \", {topK: 3})\" + \\\n",
    "        \" YIELD node, score RETURN node, score\"\n",
    "    \n",
    "    response = graph_client.execute_query(\n",
    "        graphIdentifier=config['neptune']['graphid'],\n",
    "        queryString=q,\n",
    "        language='OPEN_CYPHER',\n",
    "    )\n",
    "    return json.loads(response['payload'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_vector_search(graph_client, text_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90983ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graph_vector_search(graph_client, text_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g['results'][0]['node']['~properties']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = query_graph(graph_client, \"MATCH (src {name: 'albitar_oncology_consulting'}) MATCH (src)-[rel]-(tgt) RETURN src,rel,tgt\")\n",
    "r['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d404569-f23c-4313-8379-d3a19cc4fc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_claude_graph_rag(query, relationships):\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "\n",
    "Below is a question asked by a person. In order to help you answer, we include related relationship information the concepts in the question, extracted from a knowledge graph. Use the information from the knowledge graph to answer the question.\n",
    "\n",
    "Here's an example.\n",
    "\n",
    "<example_question>\n",
    "Can you tell me about Acme Corp?\n",
    "</example_question>\n",
    "\n",
    "<example_relationships>\n",
    "{'src': {'name': 'acme_corp'}, 'rel': ({'name': 'acme_corp'}, 'leadership', {'name': 'john_doe'}), 'tgt': {'name': 'john_doe'}}\n",
    "</example_relationships>\n",
    "\n",
    "<example_output>\n",
    "Acme Corp employes John Doe as a senior leader.\n",
    "</example_output>\n",
    "\n",
    "<question>\n",
    "QUESTION_HERE\n",
    "</question>\n",
    "\n",
    "<relationships>\n",
    "RELS_HERE\n",
    "</relationships>\n",
    "\n",
    "Be concise.\n",
    "\"\"\"\n",
    "    if isinstance(relationships, list):\n",
    "        rel_str =  \"\\n\".join([json.dumps(x) for x in relationships])\n",
    "        prompt = prompt_template.replace(\"QUESTION_HERE\", query).replace(\"RELS_HERE\", rel_str)\n",
    "    else:\n",
    "        prompt = prompt_template.replace(\"QUESTION_HERE\", query).replace(\"RELS_HERE\", json.dumps(relationships))\n",
    "    claudePayload = json.dumps({ \n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        'max_tokens': 2048,\n",
    "    \t\"messages\": [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=claudePayload, \n",
    "        modelId=claudeModelId, \n",
    "        accept='application/json', \n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    body = response.get('body').read().decode('utf-8')\n",
    "\n",
    "    response_body = json.loads(body)\n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f38d8-f98c-4bac-a016-092964f6cc91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_rag(query):\n",
    "    q_embed = call_embed(query)\n",
    "    related_nodes = graph_vector_search(graph_client, q_embed)\n",
    "    \n",
    "    subgraphs = []\n",
    "    for c in related_nodes['results']:\n",
    "        nid = c['node']['~properties']['name']\n",
    "        records = query_graph(graph_client, \n",
    "            \"MATCH (src {name: '\" + nid + \"'}) MATCH (src)-[rel]-(tgt) RETURN src,rel,tgt\"\n",
    "        )\n",
    "    \n",
    "        for r in records['results']:\n",
    "            subgraphs.append(r)\n",
    "    \n",
    "    print(f\"Found {len(subgraphs)} subgraphs\")\n",
    "    print(subgraphs)\n",
    "    return call_claude_graph_rag(query, subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9d59f-2516-45e8-9303-6534a49aac0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_rag(\"Which executives work at Albitar Oncology?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a981fa-6c63-472e-b472-cd3649af4013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
